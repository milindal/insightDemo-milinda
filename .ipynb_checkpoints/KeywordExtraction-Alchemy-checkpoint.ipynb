{
 "metadata": {
  "name": "",
  "signature": "sha256:8f4f2e4937a275b54626a5785148c6dec306c35f32cbb20d8da70bde57066668"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import sys\n",
      "import string\n",
      "sys.path.insert(0, '/Users/milindal/Dropbox/Insight/insightDemo-milinda/alchemy-test/alchemyapi_python/')\n",
      "from alchemyapi import AlchemyAPI\n",
      "alchemyapi = AlchemyAPI()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib2 import Request, urlopen, URLError\n",
      "import numpy as np \n",
      "import json \n",
      "import pandas as pd \n",
      "import matplotlib.pyplot as plt \n",
      "import gensim as gs\n",
      "import nltk\n",
      "from sklearn.cluster import KMeans\n",
      "import pickle\n",
      "import string \n",
      "import re\n",
      "import random\n",
      "%matplotlib inline "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# helper functions to clean the data\n",
      "def striphtml(data):\n",
      "    p = re.compile(r'<.*?>')\n",
      "    return p.sub('', data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords\n",
      "stop_words = set(stopwords.words('english'))\n",
      "print len(stop_words)\n",
      "print stop_words\n",
      "stop_words.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}'])\n",
      "stop_words.update(['``', \"''\", '.', ',', '!', ':', '[', ']', '...', \"\\'\\'\" , '', 'would'])\n",
      "print len(stop_words)\n",
      "print stop_words\n",
      "# stop_words = set(stopwords.words('english')).union(set(['``', \"''\", '.', ',', '!', ':', '[', ']', '...', \"\\'\\'\" , '', 'would', 'the']))\n",
      "\n",
      "# Stemming words (or not?)\n",
      "from nltk.stem import PorterStemmer\n",
      "ps = PorterStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "127\n",
        "set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'herself', u'had', u'should', u'to', u'only', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'did', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'doing', u'some', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u'does', u'above', u'between', u't', u'be', u'we', u'who', u'were', u'here', u'hers', u'by', u'on', u'about', u'of', u'against', u's', u'or', u'own', u'into', u'yourself', u'down', u'your', u'from', u'her', u'their', u'there', u'been', u'whom', u'too', u'themselves', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'myself', u'these', u'up', u'will', u'below', u'can', u'theirs', u'my', u'and', u'then', u'is', u'am', u'it', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'yours', u'so', u'the', u'having', u'once'])\n",
        "146\n",
        "set(['', u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'herself', u'had', ',', u'should', u'to', u'only', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'did', u'this', u'she', u'each', u'further', u'where', u'few', u'because', u'doing', u'some', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u'does', u'above', u'between', ';', '?', u't', u'be', u'we', u'who', u'were', u'here', u'hers', '[', u'by', u'on', u'about', 'would', u'of', u'against', u's', '(', '{', u'or', u'own', u'into', u'yourself', u'down', u'your', '\"', u'from', u'her', u'their', u'there', u'been', '.', u'whom', u'too', u'themselves', ':', u'was', u'until', u'more', '``', u'himself', u'that', u'but', '...', u'don', u'with', u'than', u'those', u'he', u'me', u'myself', u'these', u'up', u'will', u'below', u'can', u'theirs', u'my', u'and', u'then', u'is', u'am', u'it', u'an', \"''\", u'as', u'itself', u'at', u'have', u'in', u'any', u'if', '!', u'again', u'no', ')', u'when', u'same', u'how', u'other', u'which', u'you', u'after', u'most', u'such', ']', u'why', u'a', u'off', \"'\", u'i', u'yours', u'so', u'the', '}', u'having', u'once'])\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getKeywords(comment_text):\n",
      "\tresponse = alchemyapi.keywords('text', comment_text) #, {'sentiment': 1})\n",
      "\tkw = []\n",
      "\tif response['status'] == 'OK':\n",
      "\t\t#print('## Response Object ##')\n",
      "\t\t#print(json.dumps(response', indent=4))\n",
      "\t\ttry:\n",
      "\t\t\t# if response[\"keywords\"]:\n",
      "\t\t\tfor keyword in response['keywords']:\n",
      "\t\t\t\t#print(keyword['text'].encode('utf-8')', keyword['relevance'])\n",
      "\t\t\t\ts = filter(lambda x: not x.isdigit(), keyword['text'].encode('utf-8').lower())\n",
      "\t\t\t\tfor c in string.punctuation:\n",
      "\t\t\t\t\ts= s.replace(c,\"\")\n",
      "\t\t\t\tif s:\n",
      "\t\t\t\t\tkw.append(s)\n",
      "\t\t\t\tif len(kw) == 10:\n",
      "\t\t\t\t\treturn kw\n",
      "\t\texcept KeyError:\n",
      "\t\t\tpass\n",
      "\telse:\n",
      "\t\tprint('Error in keyword extaction call: ', response['statusInfo'])\n",
      "\t\tif response['statusInfo'] == 'daily-transaction-limit-exceeded':\n",
      "\t\t\treturn ['limit-exceeded']\n",
      "\t\treturn ['alchemyAPI-error']\n",
      "\n",
      "\treturn kw[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "database_dict = pickle.load(open('data/updated_database_dict.p', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the url list\n",
      "urls_list = [line.rstrip('\\n') for line in open('data/URLStest.txt').readlines() if len(line) > 5] \n",
      "urls_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "['http://www.nytimes.com/2015/09/11/us/politics/iran-nuclear-deal-senate.html',\n",
        " 'http://www.nytimes.com/2015/09/12/health/blood-pressure-study.html',\n",
        " 'http://www.nytimes.com/2012/06/26/us/supreme-court-rejects-part-of-arizona-immigration-law.html',\n",
        " 'http://www.nytimes.com/2015/06/15/opinion/workers-betrayed-by-visa-loopholes.html',\n",
        " 'http://www.nytimes.com/2015/09/15/world/europe/europe-migrants-germany.html',\n",
        " 'http://www.nytimes.com/2015/07/22/opinion/the-campaign-of-deception-against-planned-parenthood.html',\n",
        " 'http://www.nytimes.com/2015/06/05/opinion/edward-snowden-the-world-says-no-to-surveillance.html',\n",
        " 'http://www.nytimes.com/2015/09/20/opinion/sunday/a-toxic-work-world.html',\n",
        " 'http://www.nytimes.com/2015/08/16/technology/inside-amazon-wrestling-big-ideas-in-a-bruising-workplace.html']"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url_string = urls_list[-2]\n",
      "print url_string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://www.nytimes.com/2015/09/20/opinion/sunday/a-toxic-work-world.html\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the three most diverse trusted comments assosciated with the url string\n",
      "comments_df = database_dict[url_string]['comments_df']\n",
      "comment_bodies = comments_df['commentBody']\n",
      "\n",
      "# round 1: tokenizing, stemming, removing html tags and stop words\n",
      "# comment_texts = [[ps.stem(filter(lambda x: x in string.printable, word).lower()) for word in nltk.word_tokenize(striphtml(comment)) \n",
      "#               if word not in stop_words] for comment in comment_bodies]\n",
      "comment_texts = [[filter(lambda x: x in string.printable, word).lower() for word in nltk.word_tokenize(striphtml(comment)) \n",
      "                  if word not in stop_words] for comment in comment_bodies]\n",
      "#     print len(comment_texts)\n",
      "\n",
      "# round 2: filtering, remove words from comments that are too short or which are not alphabets\n",
      "comment_texts = [ [word for word in comment if (len(word) > 2 and not word.isdigit() and word not in stop_words)] for comment in comment_texts]\n",
      "#     print comment_texts[0:5]\n",
      "\n",
      "# create a dictionary for the words that appear in the comments \n",
      "dictionary = gs.corpora.Dictionary(comment_texts)\n",
      "\n",
      "# Bag of words representation for the comments \n",
      "comment_corpus = [dictionary.doc2bow(text) for text in comment_texts]\n",
      "\n",
      " # Train tf-idf model on the comment_corpus\n",
      "tfidf = gs.models.TfidfModel(comment_corpus)\n",
      "corpus_tfidf = tfidf[comment_corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getKeywords(comment_bodies[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "['br',\n",
        " 'wage inequities',\n",
        " 'lifestyle choices',\n",
        " 'greater benefits',\n",
        " 'single breadwinner',\n",
        " 'certain workers',\n",
        " 'young people',\n",
        " 'equal work',\n",
        " 'financial stress',\n",
        " 'life style']"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from textblob import TextBlob"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comment_blob = TextBlob(comment_bodies[0])\n",
      "print comment_blob.noun_phrases"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'article pits childfree', u'young people', u'< br/ > < br/ >', u'certain workers', u'america', u'wage inequities', u'equal work', u'lifestyle choices', u'< br/ > < br/ >', u'< br/ >', u'< br/ > < br/ >', u'pick', u'financial stress', u'la', u'ny', u'life style', u'single breadwinner', u'< br/ > < br/ >', u'government policy', u'work places', u'average american agrees']\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}