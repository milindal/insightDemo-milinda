{
 "metadata": {
  "name": "",
  "signature": "sha256:867bb99e02770cd259ca7e953805d749868621250aa5f9951fb17ad42ebe5d8e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data Processing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logging\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from urllib2 import Request, urlopen, URLError\n",
      "import numpy as np \n",
      "import json \n",
      "import pandas as pd \n",
      "import matplotlib.pyplot as plt \n",
      "import gensim as gs\n",
      "import nltk\n",
      "from sklearn.cluster import KMeans\n",
      "import pickle\n",
      "import string \n",
      "import re\n",
      "%matplotlib inline "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# helper functions to clean the data\n",
      "def striphtml(data):\n",
      "    p = re.compile(r'<.*?>')\n",
      "    return p.sub('', data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nltk.corpus import stopwords\n",
      "stop_words = set(stopwords.words('english')).union(set(['``', \"''\", '.', ',', '!', ':', '[', ']', '...', \"\\'\\'\" , '']))\n",
      "\n",
      "# Stemming words (or not?)\n",
      "from nltk.stem import PorterStemmer\n",
      "ps = PorterStemmer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "database_dict = pickle.load(open('data/database_dict.p', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ProcessComments(url_string): \n",
      "    # Get the comments assosciated with the url string\n",
      "    comment_df = database_dict[url_string]['comment_df']\n",
      "    comment_bodies = comment_df['commentBody']\n",
      "    \n",
      "    # round 1: tokenizing, stemming, removing html tags and stop words\n",
      "    comment_texts = [[ps.stem(filter(lambda x: x in string.printable, word).lower()) for word in nltk.word_tokenize(striphtml(comment)) \n",
      "                  if word not in stop_words] for comment in comment_bodies]\n",
      "    print len(comment_texts)\n",
      "\n",
      "    # round 2: filtering, remove words from comments that are too short or which are not alphabets\n",
      "    comment_texts = [ [word for word in comment if (len(word) > 2 and not word.isdigit())] for comment in comment_texts]\n",
      "    print comment_texts[0:5]\n",
      "    \n",
      "    # create a dictionary for the words that appear in the comments \n",
      "    dictionary = gs.corpora.Dictionary(comment_texts)\n",
      "\n",
      "    # Bag of words representation for the comments \n",
      "    comment_corpus = [dictionary.doc2bow(text) for text in comment_texts]\n",
      "    \n",
      "    # Train tf-idf model on the comment_corpus\n",
      "    tfidf = gs.models.TfidfModel(comment_corpus)\n",
      "    corpus_tfidf = tfidf[comment_corpus]\n",
      "    \n",
      "    # initialize an LSI transformation\n",
      "    lsi = gs.models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=5) \n",
      "    corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi\n",
      "    lsi.print_topics(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}